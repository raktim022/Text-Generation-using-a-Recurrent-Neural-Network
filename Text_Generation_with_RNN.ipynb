{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Generation with RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<b>Loading the text</b>"
      ],
      "metadata": {
        "id": "i7MFISssnDTO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "UwIzvhMBbbw_"
      },
      "outputs": [],
      "source": [
        "#Opening the text file\n",
        "with open('Murakami_test.txt','r') as f:\n",
        "  doc=f.read()\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#importing spaCy and loading the English library\n",
        "import spacy\n",
        "nlp=spacy.load('en_core_web_sm')"
      ],
      "metadata": {
        "id": "ZvUM25dWbtj2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "<b>Tokenization</b>"
      ],
      "metadata": {
        "id": "HziqF9mpnJog"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Tokenizing the text and removing punctuations\n",
        "words=[word.text.lower() for word in nlp(doc) if word.text not in '\\n\\n \\n\\n\\n!\"-#$%&()--.*+,-/:;<=>?@[\\\\]^_`{|}~\\t\\n']"
      ],
      "metadata": {
        "id": "lqvVc8NYb4YS"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "words"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Oaumvubub_WW",
        "outputId": "855946e4-ee28-43e2-9739-69662773eceb"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'rang',\n",
              " 'i',\n",
              " 'was',\n",
              " 'in',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " 'boiling',\n",
              " 'a',\n",
              " 'potrul',\n",
              " 'of',\n",
              " 'spaghetti',\n",
              " 'and',\n",
              " 'whistling',\n",
              " 'along',\n",
              " 'with',\n",
              " 'an',\n",
              " 'fm',\n",
              " 'broadcast',\n",
              " 'of',\n",
              " 'the',\n",
              " 'overture',\n",
              " 'to',\n",
              " 'rossini',\n",
              " '’s',\n",
              " 'the',\n",
              " 'thieving',\n",
              " 'magpie',\n",
              " 'which',\n",
              " 'has',\n",
              " 'to',\n",
              " 'be',\n",
              " 'the',\n",
              " 'perfect',\n",
              " 'music',\n",
              " 'for',\n",
              " 'cooking',\n",
              " 'pasta',\n",
              " 'i',\n",
              " 'wanted',\n",
              " 'to',\n",
              " 'ignore',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'not',\n",
              " 'only',\n",
              " 'because',\n",
              " 'the',\n",
              " 'spaghetti',\n",
              " 'was',\n",
              " 'nearly',\n",
              " 'done',\n",
              " 'but',\n",
              " 'because',\n",
              " 'claudio',\n",
              " 'abbado',\n",
              " 'was',\n",
              " 'bringing',\n",
              " 'the',\n",
              " 'london',\n",
              " 'symphony',\n",
              " 'to',\n",
              " 'its',\n",
              " 'musical',\n",
              " 'climax',\n",
              " 'finally',\n",
              " 'though',\n",
              " 'i',\n",
              " 'had',\n",
              " 'to',\n",
              " 'give',\n",
              " 'in',\n",
              " 'it',\n",
              " 'could',\n",
              " 'have',\n",
              " 'been',\n",
              " 'somebody',\n",
              " 'with',\n",
              " 'news',\n",
              " 'of',\n",
              " 'a',\n",
              " 'job',\n",
              " 'opening',\n",
              " 'i',\n",
              " 'lowered',\n",
              " 'the',\n",
              " 'flame',\n",
              " 'went',\n",
              " 'to',\n",
              " 'the',\n",
              " 'living',\n",
              " 'room',\n",
              " 'and',\n",
              " 'picked',\n",
              " 'up',\n",
              " 'the',\n",
              " 'receiver',\n",
              " '“',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'please',\n",
              " '”',\n",
              " 'said',\n",
              " 'a',\n",
              " 'woman',\n",
              " 'on',\n",
              " 'the',\n",
              " 'other',\n",
              " 'end',\n",
              " 'i',\n",
              " '’m',\n",
              " 'good',\n",
              " 'at',\n",
              " 'recognizing',\n",
              " 'people',\n",
              " '’s',\n",
              " 'voices',\n",
              " 'but',\n",
              " 'this',\n",
              " 'was',\n",
              " 'not',\n",
              " 'one',\n",
              " 'i',\n",
              " 'knew',\n",
              " '“',\n",
              " 'excuse',\n",
              " 'me',\n",
              " 'to',\n",
              " 'whom',\n",
              " 'did',\n",
              " 'you',\n",
              " 'wish',\n",
              " 'to',\n",
              " 'speak',\n",
              " '”',\n",
              " '“',\n",
              " 'to',\n",
              " 'you',\n",
              " 'of',\n",
              " 'course',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'please',\n",
              " 'that',\n",
              " '’s',\n",
              " 'all',\n",
              " 'we',\n",
              " 'need',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'each',\n",
              " 'other',\n",
              " '”',\n",
              " 'her',\n",
              " 'voice',\n",
              " 'was',\n",
              " 'low',\n",
              " 'and',\n",
              " 'soft',\n",
              " 'but',\n",
              " 'otherwise',\n",
              " 'nondescript',\n",
              " '“',\n",
              " 'understand',\n",
              " 'each',\n",
              " 'other',\n",
              " '”',\n",
              " '“',\n",
              " 'each',\n",
              " 'other',\n",
              " '’s',\n",
              " 'feelings',\n",
              " 'i',\n",
              " 'leaned',\n",
              " 'over',\n",
              " 'and',\n",
              " 'peeked',\n",
              " 'through',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " 'door',\n",
              " 'the',\n",
              " 'spaghetti',\n",
              " 'pot',\n",
              " 'was',\n",
              " 'steaming',\n",
              " 'nicely',\n",
              " 'and',\n",
              " 'claudio',\n",
              " 'abbado',\n",
              " 'was',\n",
              " 'still',\n",
              " 'conducting',\n",
              " 'the',\n",
              " 'thieving',\n",
              " 'magpie',\n",
              " '“',\n",
              " 'sorry',\n",
              " 'but',\n",
              " 'you',\n",
              " 'caught',\n",
              " 'me',\n",
              " 'in',\n",
              " 'the',\n",
              " 'middle',\n",
              " 'of',\n",
              " 'making',\n",
              " 'spaghetti',\n",
              " 'can',\n",
              " 'i',\n",
              " 'ask',\n",
              " 'you',\n",
              " 'to',\n",
              " 'call',\n",
              " 'back',\n",
              " 'later',\n",
              " '”',\n",
              " '“',\n",
              " 'spaghetti',\n",
              " 'what',\n",
              " 'are',\n",
              " 'you',\n",
              " 'doing',\n",
              " 'cooking',\n",
              " 'spaghetti',\n",
              " 'at',\n",
              " 'ten',\n",
              " 'thirty',\n",
              " 'in',\n",
              " 'the',\n",
              " 'morning',\n",
              " '”',\n",
              " '“',\n",
              " 'that',\n",
              " '’s',\n",
              " 'none',\n",
              " 'of',\n",
              " 'your',\n",
              " 'business',\n",
              " '”',\n",
              " 'i',\n",
              " 'said',\n",
              " '“',\n",
              " 'i',\n",
              " 'decide',\n",
              " 'what',\n",
              " 'i',\n",
              " 'eat',\n",
              " 'and',\n",
              " 'when',\n",
              " 'i',\n",
              " 'eat',\n",
              " 'it',\n",
              " '”',\n",
              " '“',\n",
              " 'true',\n",
              " 'enough',\n",
              " 'i',\n",
              " '’ll',\n",
              " 'call',\n",
              " 'back',\n",
              " '”',\n",
              " 'she',\n",
              " 'said',\n",
              " 'her',\n",
              " 'voice',\n",
              " 'now',\n",
              " 'flat',\n",
              " 'and',\n",
              " 'expressionless',\n",
              " 'a',\n",
              " 'little',\n",
              " 'change',\n",
              " 'in',\n",
              " 'mood',\n",
              " 'can',\n",
              " 'do',\n",
              " 'amazing',\n",
              " 'things',\n",
              " 'to',\n",
              " 'the',\n",
              " 'tone',\n",
              " 'of',\n",
              " 'a',\n",
              " 'person',\n",
              " '’s',\n",
              " 'voice',\n",
              " '“',\n",
              " 'hold',\n",
              " 'on',\n",
              " 'a',\n",
              " 'minute',\n",
              " '”',\n",
              " 'i',\n",
              " 'said',\n",
              " 'before',\n",
              " 'she',\n",
              " 'could',\n",
              " 'hang',\n",
              " 'up',\n",
              " '“',\n",
              " 'if',\n",
              " 'this',\n",
              " 'is',\n",
              " 'some',\n",
              " 'new',\n",
              " 'sales',\n",
              " 'gimmick',\n",
              " 'you',\n",
              " 'can',\n",
              " 'forget',\n",
              " 'it',\n",
              " 'i',\n",
              " '’m',\n",
              " 'out',\n",
              " 'of',\n",
              " 'work',\n",
              " 'i',\n",
              " '’m',\n",
              " 'not',\n",
              " 'in',\n",
              " 'the',\n",
              " 'market',\n",
              " 'for',\n",
              " 'anything',\n",
              " '”',\n",
              " '“',\n",
              " 'do',\n",
              " 'n’t',\n",
              " 'worry',\n",
              " 'i',\n",
              " 'know',\n",
              " '”',\n",
              " '“',\n",
              " 'you',\n",
              " 'know',\n",
              " 'you',\n",
              " 'know',\n",
              " 'what',\n",
              " '”',\n",
              " '“',\n",
              " 'that',\n",
              " 'you',\n",
              " '’re',\n",
              " 'out',\n",
              " 'of',\n",
              " 'work',\n",
              " 'i',\n",
              " 'know',\n",
              " 'about',\n",
              " 'that',\n",
              " 'so',\n",
              " 'go',\n",
              " 'cook',\n",
              " 'your',\n",
              " 'precious',\n",
              " 'spaghetti',\n",
              " '”',\n",
              " '“',\n",
              " 'who',\n",
              " 'the',\n",
              " 'hell-',\n",
              " '”',\n",
              " 'she',\n",
              " 'cut',\n",
              " 'the',\n",
              " 'connection',\n",
              " 'with',\n",
              " 'no',\n",
              " 'outlet',\n",
              " 'for',\n",
              " 'my',\n",
              " 'feelings',\n",
              " 'i',\n",
              " 'stared',\n",
              " 'at',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'in',\n",
              " 'my',\n",
              " 'hand',\n",
              " 'until',\n",
              " 'i',\n",
              " 'remembered',\n",
              " 'the',\n",
              " 'spaghetti',\n",
              " 'back',\n",
              " 'in',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " 'i',\n",
              " 'turned',\n",
              " 'off',\n",
              " 'the',\n",
              " 'gas',\n",
              " 'and',\n",
              " 'poured',\n",
              " 'the',\n",
              " 'contents',\n",
              " 'of',\n",
              " 'the',\n",
              " 'pot',\n",
              " 'into',\n",
              " 'a',\n",
              " 'colander',\n",
              " 'thanks',\n",
              " 'to',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'call',\n",
              " 'the',\n",
              " 'spaghetti',\n",
              " 'was',\n",
              " 'a',\n",
              " 'little',\n",
              " 'softer',\n",
              " 'than',\n",
              " 'al',\n",
              " 'dente',\n",
              " 'but',\n",
              " 'it',\n",
              " 'had',\n",
              " 'not',\n",
              " 'been',\n",
              " 'dealt',\n",
              " 'a',\n",
              " 'mortal',\n",
              " 'blow',\n",
              " 'i',\n",
              " 'started',\n",
              " 'eating',\n",
              " 'and',\n",
              " 'thinking',\n",
              " 'understand',\n",
              " 'each',\n",
              " 'other',\n",
              " 'understand',\n",
              " 'each',\n",
              " 'other',\n",
              " '’s',\n",
              " 'feelings',\n",
              " 'in',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'what',\n",
              " 'was',\n",
              " 'she',\n",
              " 'talking',\n",
              " 'about',\n",
              " 'maybe',\n",
              " 'it',\n",
              " 'was',\n",
              " 'just',\n",
              " 'a',\n",
              " 'prank',\n",
              " 'call',\n",
              " 'or',\n",
              " 'some',\n",
              " 'new',\n",
              " 'sales',\n",
              " 'pitch',\n",
              " 'in',\n",
              " 'any',\n",
              " 'case',\n",
              " 'it',\n",
              " 'had',\n",
              " 'nothing',\n",
              " 'to',\n",
              " 'do',\n",
              " 'with',\n",
              " 'me',\n",
              " 'after',\n",
              " 'lunch',\n",
              " 'i',\n",
              " 'went',\n",
              " 'back',\n",
              " 'to',\n",
              " 'my',\n",
              " 'library',\n",
              " 'novel',\n",
              " 'on',\n",
              " 'the',\n",
              " 'living',\n",
              " 'room',\n",
              " 'sofa',\n",
              " 'glancing',\n",
              " 'every',\n",
              " 'now',\n",
              " 'and',\n",
              " 'then',\n",
              " 'at',\n",
              " 'the',\n",
              " 'telephone',\n",
              " 'what',\n",
              " 'were',\n",
              " 'we',\n",
              " 'supposed',\n",
              " 'to',\n",
              " 'understand',\n",
              " 'about',\n",
              " 'each',\n",
              " 'other',\n",
              " 'in',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'what',\n",
              " 'can',\n",
              " 'two',\n",
              " 'people',\n",
              " 'understand',\n",
              " 'about',\n",
              " 'each',\n",
              " 'other',\n",
              " 'in',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'come',\n",
              " 'to',\n",
              " 'think',\n",
              " 'of',\n",
              " 'it',\n",
              " 'she',\n",
              " 'seemed',\n",
              " 'awfully',\n",
              " 'sure',\n",
              " 'about',\n",
              " 'those',\n",
              " 'ten',\n",
              " 'minutes',\n",
              " 'it',\n",
              " 'was',\n",
              " 'the',\n",
              " 'first',\n",
              " 'thing',\n",
              " 'out',\n",
              " 'of',\n",
              " 'her',\n",
              " 'mouth',\n",
              " 'as',\n",
              " 'if',\n",
              " 'nine',\n",
              " 'minutes',\n",
              " 'would',\n",
              " 'be',\n",
              " 'too',\n",
              " 'short',\n",
              " 'or',\n",
              " 'eleven',\n",
              " 'minutes',\n",
              " 'too',\n",
              " 'long',\n",
              " 'like',\n",
              " 'cooking',\n",
              " 'spaghetti',\n",
              " 'al',\n",
              " 'dente',\n",
              " 'i',\n",
              " 'could',\n",
              " 'n’t',\n",
              " 'read',\n",
              " 'anymore',\n",
              " 'i',\n",
              " 'decided',\n",
              " 'to',\n",
              " 'iron',\n",
              " 'shirts',\n",
              " 'instead',\n",
              " 'which',\n",
              " 'is',\n",
              " 'what',\n",
              " 'i',\n",
              " 'always',\n",
              " 'do',\n",
              " 'when',\n",
              " 'i',\n",
              " '’m',\n",
              " 'upset',\n",
              " 'it',\n",
              " '’s',\n",
              " 'an',\n",
              " 'old',\n",
              " 'habit',\n",
              " 'i',\n",
              " 'divide',\n",
              " 'the',\n",
              " 'job',\n",
              " 'into',\n",
              " 'twelve',\n",
              " 'precise',\n",
              " 'stages',\n",
              " 'beginning',\n",
              " 'with',\n",
              " 'the',\n",
              " 'collar',\n",
              " 'outer',\n",
              " 'surface',\n",
              " 'and',\n",
              " 'ending',\n",
              " 'with',\n",
              " 'the',\n",
              " 'left',\n",
              " 'hand',\n",
              " 'cuff',\n",
              " 'the',\n",
              " 'order',\n",
              " 'is',\n",
              " 'always',\n",
              " 'the',\n",
              " 'same',\n",
              " 'and',\n",
              " 'i',\n",
              " 'count',\n",
              " 'off',\n",
              " 'each',\n",
              " 'stage',\n",
              " 'to',\n",
              " 'myself',\n",
              " 'otherwise',\n",
              " 'it',\n",
              " 'wo',\n",
              " 'n’t',\n",
              " 'come',\n",
              " 'out',\n",
              " 'right',\n",
              " 'i',\n",
              " 'ironed',\n",
              " 'three',\n",
              " 'shirts',\n",
              " 'checking',\n",
              " 'them',\n",
              " 'over',\n",
              " 'for',\n",
              " 'wrinkles',\n",
              " 'and',\n",
              " 'putting',\n",
              " 'them',\n",
              " 'on',\n",
              " 'hangers',\n",
              " 'once',\n",
              " 'i',\n",
              " 'had',\n",
              " 'switched',\n",
              " 'off',\n",
              " 'the',\n",
              " 'iron',\n",
              " 'and',\n",
              " 'put',\n",
              " 'it',\n",
              " 'away',\n",
              " 'with',\n",
              " 'the',\n",
              " 'ironing',\n",
              " 'board',\n",
              " 'in',\n",
              " 'the',\n",
              " 'hall',\n",
              " 'closet',\n",
              " 'my',\n",
              " 'mind',\n",
              " 'felt',\n",
              " 'a',\n",
              " 'good',\n",
              " 'deal',\n",
              " 'clearer',\n",
              " 'i',\n",
              " 'was',\n",
              " 'on',\n",
              " 'my',\n",
              " 'way',\n",
              " 'to',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " 'for',\n",
              " 'a',\n",
              " 'glass',\n",
              " 'of',\n",
              " 'water',\n",
              " 'when',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'rang',\n",
              " 'again',\n",
              " 'i',\n",
              " 'hesitated',\n",
              " 'for',\n",
              " 'a',\n",
              " 'second',\n",
              " 'but',\n",
              " 'decided',\n",
              " 'to',\n",
              " 'answer',\n",
              " 'it',\n",
              " 'if',\n",
              " 'it',\n",
              " 'was',\n",
              " 'the',\n",
              " 'same',\n",
              " 'woman',\n",
              " 'i',\n",
              " '’d',\n",
              " 'tell',\n",
              " 'her',\n",
              " 'i',\n",
              " 'was',\n",
              " 'ironing',\n",
              " 'and',\n",
              " 'hang',\n",
              " 'up',\n",
              " 'this',\n",
              " 'time',\n",
              " 'it',\n",
              " 'was',\n",
              " 'kumiko',\n",
              " 'the',\n",
              " 'wall',\n",
              " 'clock',\n",
              " 'said',\n",
              " 'eleven',\n",
              " 'thirty',\n",
              " '“',\n",
              " 'how',\n",
              " 'are',\n",
              " 'you',\n",
              " '”',\n",
              " 'she',\n",
              " 'asked',\n",
              " '“',\n",
              " 'fine',\n",
              " '”',\n",
              " 'i',\n",
              " 'said',\n",
              " 'relieved',\n",
              " 'to',\n",
              " 'hear',\n",
              " 'my',\n",
              " 'wife',\n",
              " '’s',\n",
              " 'voice',\n",
              " '“',\n",
              " 'what',\n",
              " 'are',\n",
              " 'you',\n",
              " 'doing',\n",
              " '”',\n",
              " '“',\n",
              " 'just',\n",
              " 'finished',\n",
              " 'ironing',\n",
              " '”',\n",
              " '“',\n",
              " 'what',\n",
              " '’s',\n",
              " 'wrong',\n",
              " '”',\n",
              " 'there',\n",
              " 'was',\n",
              " 'a',\n",
              " 'note',\n",
              " 'of',\n",
              " 'tension',\n",
              " 'in',\n",
              " 'her',\n",
              " 'voice',\n",
              " 'she',\n",
              " 'knew',\n",
              " 'what',\n",
              " 'it',\n",
              " 'meant',\n",
              " 'for',\n",
              " 'me',\n",
              " 'to',\n",
              " 'be',\n",
              " 'ironing',\n",
              " '“',\n",
              " 'nothing',\n",
              " 'i',\n",
              " 'was',\n",
              " 'just',\n",
              " 'ironing',\n",
              " 'some',\n",
              " 'shirts',\n",
              " '”',\n",
              " 'i',\n",
              " 'sat',\n",
              " 'down',\n",
              " 'and',\n",
              " 'shifted',\n",
              " 'the',\n",
              " 'receiver',\n",
              " 'from',\n",
              " 'my',\n",
              " 'left',\n",
              " 'hand',\n",
              " 'to',\n",
              " 'my',\n",
              " 'right',\n",
              " '“',\n",
              " 'what',\n",
              " '’s',\n",
              " 'up',\n",
              " '”',\n",
              " '“',\n",
              " 'can',\n",
              " 'you',\n",
              " 'write',\n",
              " 'poetry',\n",
              " '”',\n",
              " 'she',\n",
              " 'asked',\n",
              " '“',\n",
              " 'poetry',\n",
              " '”',\n",
              " 'poetry',\n",
              " 'did',\n",
              " 'she',\n",
              " 'mean',\n",
              " '...',\n",
              " 'poetry',\n",
              " '“',\n",
              " 'i',\n",
              " 'know',\n",
              " 'the',\n",
              " 'publisher',\n",
              " 'of',\n",
              " 'a',\n",
              " 'story',\n",
              " 'magazine',\n",
              " 'for',\n",
              " 'girls',\n",
              " 'they',\n",
              " '’re',\n",
              " 'looking',\n",
              " 'for',\n",
              " 'somebody',\n",
              " 'to',\n",
              " 'pick',\n",
              " 'and',\n",
              " 'revise',\n",
              " 'poems',\n",
              " 'submitted',\n",
              " 'by',\n",
              " 'readers',\n",
              " 'and',\n",
              " 'they',\n",
              " 'want',\n",
              " 'the',\n",
              " 'person',\n",
              " 'to',\n",
              " 'write',\n",
              " 'a',\n",
              " 'short',\n",
              " 'poem',\n",
              " 'every',\n",
              " 'month',\n",
              " 'for',\n",
              " 'the',\n",
              " 'frontispiece',\n",
              " 'pay',\n",
              " '’s',\n",
              " 'not',\n",
              " 'bad',\n",
              " 'for',\n",
              " 'an',\n",
              " 'easy',\n",
              " 'job',\n",
              " 'of',\n",
              " 'course',\n",
              " 'it',\n",
              " '’s',\n",
              " 'part',\n",
              " 'time',\n",
              " 'but',\n",
              " 'they',\n",
              " 'might',\n",
              " 'add',\n",
              " 'some',\n",
              " 'editorial',\n",
              " 'work',\n",
              " 'if',\n",
              " 'the',\n",
              " 'person-',\n",
              " '”',\n",
              " '“',\n",
              " 'easy',\n",
              " 'work',\n",
              " '”',\n",
              " 'i',\n",
              " 'broke',\n",
              " 'in',\n",
              " '“',\n",
              " 'hey',\n",
              " 'wait',\n",
              " 'a',\n",
              " 'minute',\n",
              " 'i',\n",
              " '’m',\n",
              " 'looking',\n",
              " 'for',\n",
              " 'something',\n",
              " 'in',\n",
              " 'law',\n",
              " 'not',\n",
              " 'poetry',\n",
              " '”',\n",
              " '“',\n",
              " 'i',\n",
              " 'thought',\n",
              " 'you',\n",
              " 'did',\n",
              " 'some',\n",
              " 'writing',\n",
              " 'in',\n",
              " 'high',\n",
              " 'school',\n",
              " '”',\n",
              " '“',\n",
              " 'yeah',\n",
              " 'sure',\n",
              " 'for',\n",
              " 'the',\n",
              " 'school',\n",
              " 'newspaper',\n",
              " 'which',\n",
              " 'team',\n",
              " 'won',\n",
              " 'the',\n",
              " 'soccer',\n",
              " 'championship',\n",
              " 'or',\n",
              " 'how',\n",
              " 'the',\n",
              " 'physics',\n",
              " 'teacher',\n",
              " 'fell',\n",
              " 'down',\n",
              " 'the',\n",
              " 'stairs',\n",
              " 'and',\n",
              " 'ended',\n",
              " 'up',\n",
              " 'in',\n",
              " 'the',\n",
              " 'hospital',\n",
              " 'that',\n",
              " 'kind',\n",
              " 'of',\n",
              " 'stuff',\n",
              " 'not',\n",
              " 'poetry',\n",
              " 'i',\n",
              " 'ca',\n",
              " 'n’t',\n",
              " 'write',\n",
              " 'poetry',\n",
              " '”',\n",
              " '“',\n",
              " 'sure',\n",
              " 'but',\n",
              " 'i',\n",
              " '’m',\n",
              " 'not',\n",
              " 'talking',\n",
              " 'about',\n",
              " 'great',\n",
              " 'poetry',\n",
              " 'just',\n",
              " 'something',\n",
              " 'for',\n",
              " 'high',\n",
              " 'school',\n",
              " 'girls',\n",
              " 'it',\n",
              " 'does',\n",
              " 'n’t',\n",
              " 'have',\n",
              " 'to',\n",
              " 'find',\n",
              " 'a',\n",
              " 'place',\n",
              " 'in',\n",
              " 'literary',\n",
              " 'history',\n",
              " 'you',\n",
              " 'could',\n",
              " 'do',\n",
              " 'it',\n",
              " 'with',\n",
              " 'your',\n",
              " 'eyes',\n",
              " 'closed',\n",
              " 'do',\n",
              " 'n’t',\n",
              " 'you',\n",
              " 'see',\n",
              " '”',\n",
              " '“',\n",
              " 'look',\n",
              " 'i',\n",
              " ...]"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create sequence of tokens of size 25, +1 for the label which we will predict\n",
        "word_sequences=[]\n",
        "train_len=25 + 1\n",
        "for i in range(train_len,len(words)):\n",
        "  w=words[i-train_len:i]\n",
        "  word_sequences.append(w)"
      ],
      "metadata": {
        "id": "e8WFERuUb_70"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "word_sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qj3VyI02cvb0",
        "outputId": "fdde8031-e863-4918-91be-86bfbfaf5bc8"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['when',\n",
              " 'the',\n",
              " 'phone',\n",
              " 'rang',\n",
              " 'i',\n",
              " 'was',\n",
              " 'in',\n",
              " 'the',\n",
              " 'kitchen',\n",
              " 'boiling',\n",
              " 'a',\n",
              " 'potrul',\n",
              " 'of',\n",
              " 'spaghetti',\n",
              " 'and',\n",
              " 'whistling',\n",
              " 'along',\n",
              " 'with',\n",
              " 'an',\n",
              " 'fm',\n",
              " 'broadcast',\n",
              " 'of',\n",
              " 'the',\n",
              " 'overture',\n",
              " 'to',\n",
              " 'rossini']"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Keras</b></h1>"
      ],
      "metadata": {
        "id": "Cnn7dRlnnQL0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import keras"
      ],
      "metadata": {
        "id": "3RSmnPbUdjOP"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.preprocessing.text import Tokenizer"
      ],
      "metadata": {
        "id": "ax2E0YdTc4EW"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating an instance of the tokenizer\n",
        "tokenizer=Tokenizer()"
      ],
      "metadata": {
        "id": "TxKD4mDjdZ0Z"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#fitting the tokenizer on the text\n",
        "tokenizer.fit_on_texts(word_sequences)"
      ],
      "metadata": {
        "id": "xC5zpvSXdq4o"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tokenizing the word sequences\n",
        "sequences=tokenizer.texts_to_sequences(word_sequences)"
      ],
      "metadata": {
        "id": "SmKBw-DmdzKZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wEEmnEKZeUS4",
        "outputId": "487d09fc-3ebe-4a4d-abd3-bba22bdc67f1"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59,\n",
              " 1,\n",
              " 46,\n",
              " 150,\n",
              " 2,\n",
              " 12,\n",
              " 9,\n",
              " 1,\n",
              " 58,\n",
              " 404,\n",
              " 8,\n",
              " 403,\n",
              " 10,\n",
              " 16,\n",
              " 7,\n",
              " 400,\n",
              " 399,\n",
              " 21,\n",
              " 77,\n",
              " 398,\n",
              " 397,\n",
              " 10,\n",
              " 1,\n",
              " 395,\n",
              " 5,\n",
              " 151]"
            ]
          },
          "metadata": {},
          "execution_count": 33
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[59,\n",
              " 1,\n",
              " 46,\n",
              " 150,\n",
              " 2,\n",
              " 12,\n",
              " 9,\n",
              " 1,\n",
              " 58,\n",
              " 404,\n",
              " 8,\n",
              " 403,\n",
              " 10,\n",
              " 16,\n",
              " 7,\n",
              " 400,\n",
              " 399,\n",
              " 21,\n",
              " 77,\n",
              " 398,\n",
              " 397,\n",
              " 10,\n",
              " 1,\n",
              " 395,\n",
              " 5,\n",
              " 151]"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\" \".join([tokenizer.index_word[i] for i in sequences[0]])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "3v2CLLFiei8C",
        "outputId": "0a2b01b5-2fc7-4cc0-b541-cb5369f0b0c1"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'when the phone rang i was in the kitchen boiling a potrul of spaghetti and whistling along with an fm broadcast of the overture to rossini'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#vocabulary size=number of unique words in the text\n",
        "vocab_size=len(tokenizer.word_counts)"
      ],
      "metadata": {
        "id": "bEr3DzK0ezdc"
      },
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3qPXsfifNua",
        "outputId": "a7e992af-f2fb-48ae-b8fe-14adec6bdeeb"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "406"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#converting the sequences into a matrix\n",
        "import numpy as np\n",
        "sequences=np.array(sequences)"
      ],
      "metadata": {
        "id": "Fg9pbMqKfQrV"
      },
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EpeQRztYfbYo",
        "outputId": "30e02fce-33ad-4cd8-e32a-a1f0f532c640"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[ 59,   1,  46, ..., 395,   5, 151],\n",
              "       [  1,  46, 150, ...,   5, 151,  11],\n",
              "       [ 46, 150,   2, ..., 151,  11,   1],\n",
              "       ...,\n",
              "       [  4,   3, 394, ..., 405,   7,  27],\n",
              "       [  3, 394,   2, ...,   7,  27,   3],\n",
              "       [394,   2, 396, ...,  27,   3, 406]])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Creating a Recurrent Neural Network</b></h1>"
      ],
      "metadata": {
        "id": "o_mNqdeQnW13"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#importing the layers to build an RNN\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Embedding,LSTM,Dense"
      ],
      "metadata": {
        "id": "tvlrXVdzfcdG"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#creating the RNN\n",
        "def create_model(vocabulary_size, seq_len):\n",
        "    model = Sequential()\n",
        "    model.add(Embedding(vocabulary_size, 25, input_length=seq_len))\n",
        "    model.add(LSTM(150, return_sequences=True))\n",
        "    model.add(LSTM(150))\n",
        "    model.add(Dense(150, activation='relu'))\n",
        "\n",
        "    model.add(Dense(vocabulary_size, activation='softmax'))\n",
        "    \n",
        "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "   \n",
        "    model.summary()\n",
        "    \n",
        "    return model"
      ],
      "metadata": {
        "id": "uF9bGrnVfmmv"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Splitting the matrix into input sequences and labels\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "X=sequences[:,:-1]\n",
        "y=sequences[:,-1]\n",
        "y=to_categorical(y,num_classes=vocab_size+1)"
      ],
      "metadata": {
        "id": "NhEnFxPxfryd"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len=X.shape[1]"
      ],
      "metadata": {
        "id": "kFZt7-QVf49I"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seq_len"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzo7RKnTgsIx",
        "outputId": "31fa580c-8999-46e4-b831-883f4f3dc3cb"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "25"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Creating the model\n",
        "model=create_model(vocab_size+1,seq_len)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XCjbkGyYgtFC",
        "outputId": "a041694e-5b73-49ec-a92c-5178a101e506"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 25, 25)            10175     \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 25, 150)           105600    \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 150)               180600    \n",
            "                                                                 \n",
            " dense (Dense)               (None, 150)               22650     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 407)               61457     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 380,482\n",
            "Trainable params: 380,482\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Fitting the model\n",
        "model.fit(X, y, batch_size=128, epochs=300,verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PehZ3v1WgzBc",
        "outputId": "abb1bffd-077c-4b86-8199-bcb0fcfa904a"
      },
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 5.3320 - accuracy: 0.0510\n",
            "Epoch 2/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 5.2931 - accuracy: 0.0491\n",
            "Epoch 3/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 5.2793 - accuracy: 0.0500\n",
            "Epoch 4/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2729 - accuracy: 0.0482\n",
            "Epoch 5/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2694 - accuracy: 0.0510\n",
            "Epoch 6/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2697 - accuracy: 0.0491\n",
            "Epoch 7/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 5.2669 - accuracy: 0.0482\n",
            "Epoch 8/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 5.2701 - accuracy: 0.0482\n",
            "Epoch 9/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 5.2663 - accuracy: 0.0482\n",
            "Epoch 10/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 5.2648 - accuracy: 0.0491\n",
            "Epoch 11/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 5.2670 - accuracy: 0.0352\n",
            "Epoch 12/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 5.2659 - accuracy: 0.0417\n",
            "Epoch 13/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 5.2694 - accuracy: 0.0491\n",
            "Epoch 14/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 5.2620 - accuracy: 0.0482\n",
            "Epoch 15/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 5.2623 - accuracy: 0.0482\n",
            "Epoch 16/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 5.2685 - accuracy: 0.0389\n",
            "Epoch 17/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 5.2615 - accuracy: 0.0500\n",
            "Epoch 18/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 5.2587 - accuracy: 0.0482\n",
            "Epoch 19/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2575 - accuracy: 0.0482\n",
            "Epoch 20/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2534 - accuracy: 0.0482\n",
            "Epoch 21/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 5.2465 - accuracy: 0.0491\n",
            "Epoch 22/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2364 - accuracy: 0.0399\n",
            "Epoch 23/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.2193 - accuracy: 0.0510\n",
            "Epoch 24/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 5.1889 - accuracy: 0.0380\n",
            "Epoch 25/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 5.1380 - accuracy: 0.0510\n",
            "Epoch 26/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 5.0847 - accuracy: 0.0491\n",
            "Epoch 27/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 5.0176 - accuracy: 0.0491\n",
            "Epoch 28/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 4.9673 - accuracy: 0.0473\n",
            "Epoch 29/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 4.9319 - accuracy: 0.0528\n",
            "Epoch 30/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 4.8944 - accuracy: 0.0556\n",
            "Epoch 31/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 4.8615 - accuracy: 0.0602\n",
            "Epoch 32/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 4.8195 - accuracy: 0.0528\n",
            "Epoch 33/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 4.7706 - accuracy: 0.0639\n",
            "Epoch 34/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 4.7159 - accuracy: 0.0630\n",
            "Epoch 35/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 4.6622 - accuracy: 0.0751\n",
            "Epoch 36/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 4.5984 - accuracy: 0.0621\n",
            "Epoch 37/300\n",
            "9/9 [==============================] - 2s 249ms/step - loss: 4.5410 - accuracy: 0.0751\n",
            "Epoch 38/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 4.4804 - accuracy: 0.0751\n",
            "Epoch 39/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 4.4226 - accuracy: 0.0834\n",
            "Epoch 40/300\n",
            "9/9 [==============================] - 2s 196ms/step - loss: 4.3502 - accuracy: 0.0825\n",
            "Epoch 41/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 4.2777 - accuracy: 0.0927\n",
            "Epoch 42/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 4.2177 - accuracy: 0.0908\n",
            "Epoch 43/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 4.1721 - accuracy: 0.1019\n",
            "Epoch 44/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 4.1004 - accuracy: 0.1075\n",
            "Epoch 45/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 4.0430 - accuracy: 0.1084\n",
            "Epoch 46/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 3.9924 - accuracy: 0.1112\n",
            "Epoch 47/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 3.9454 - accuracy: 0.1094\n",
            "Epoch 48/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 3.8921 - accuracy: 0.1288\n",
            "Epoch 49/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 3.8433 - accuracy: 0.1390\n",
            "Epoch 50/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 3.7959 - accuracy: 0.1316\n",
            "Epoch 51/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.7521 - accuracy: 0.1390\n",
            "Epoch 52/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 3.6963 - accuracy: 0.1538\n",
            "Epoch 53/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.6567 - accuracy: 0.1437\n",
            "Epoch 54/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 3.6138 - accuracy: 0.1622\n",
            "Epoch 55/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 3.5635 - accuracy: 0.1483\n",
            "Epoch 56/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.5135 - accuracy: 0.1501\n",
            "Epoch 57/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.4648 - accuracy: 0.1613\n",
            "Epoch 58/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 3.4265 - accuracy: 0.1557\n",
            "Epoch 59/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 3.3769 - accuracy: 0.1752\n",
            "Epoch 60/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 3.3291 - accuracy: 0.1668\n",
            "Epoch 61/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.2911 - accuracy: 0.1687\n",
            "Epoch 62/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 3.2451 - accuracy: 0.1872\n",
            "Epoch 63/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 3.2143 - accuracy: 0.1798\n",
            "Epoch 64/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 3.1791 - accuracy: 0.1872\n",
            "Epoch 65/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 3.1270 - accuracy: 0.1918\n",
            "Epoch 66/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 3.0915 - accuracy: 0.1946\n",
            "Epoch 67/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 3.0572 - accuracy: 0.1993\n",
            "Epoch 68/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 3.0168 - accuracy: 0.2095\n",
            "Epoch 69/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 2.9897 - accuracy: 0.2113\n",
            "Epoch 70/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 2.9411 - accuracy: 0.2243\n",
            "Epoch 71/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 2.9106 - accuracy: 0.2169\n",
            "Epoch 72/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.9065 - accuracy: 0.2150\n",
            "Epoch 73/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.8724 - accuracy: 0.2159\n",
            "Epoch 74/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.8165 - accuracy: 0.2437\n",
            "Epoch 75/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 2.7962 - accuracy: 0.2447\n",
            "Epoch 76/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 2.7654 - accuracy: 0.2502\n",
            "Epoch 77/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 2.7309 - accuracy: 0.2549\n",
            "Epoch 78/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.6818 - accuracy: 0.2734\n",
            "Epoch 79/300\n",
            "9/9 [==============================] - 2s 195ms/step - loss: 2.6585 - accuracy: 0.2771\n",
            "Epoch 80/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.6343 - accuracy: 0.2743\n",
            "Epoch 81/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 2.6104 - accuracy: 0.2975\n",
            "Epoch 82/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 2.5655 - accuracy: 0.3021\n",
            "Epoch 83/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 2.5399 - accuracy: 0.3068\n",
            "Epoch 84/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 2.5079 - accuracy: 0.3188\n",
            "Epoch 85/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 2.4813 - accuracy: 0.3160\n",
            "Epoch 86/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.4459 - accuracy: 0.3290\n",
            "Epoch 87/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 2.4185 - accuracy: 0.3383\n",
            "Epoch 88/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 2.3915 - accuracy: 0.3531\n",
            "Epoch 89/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.3585 - accuracy: 0.3485\n",
            "Epoch 90/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 2.3194 - accuracy: 0.3763\n",
            "Epoch 91/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 2.3041 - accuracy: 0.3614\n",
            "Epoch 92/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.2857 - accuracy: 0.3763\n",
            "Epoch 93/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 2.2551 - accuracy: 0.3874\n",
            "Epoch 94/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.2195 - accuracy: 0.3892\n",
            "Epoch 95/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.2225 - accuracy: 0.3855\n",
            "Epoch 96/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 2.1776 - accuracy: 0.3930\n",
            "Epoch 97/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 2.1588 - accuracy: 0.4143\n",
            "Epoch 98/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 2.1307 - accuracy: 0.4217\n",
            "Epoch 99/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 2.0948 - accuracy: 0.4374\n",
            "Epoch 100/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.0706 - accuracy: 0.4263\n",
            "Epoch 101/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 2.0531 - accuracy: 0.4365\n",
            "Epoch 102/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 2.0290 - accuracy: 0.4319\n",
            "Epoch 103/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.9993 - accuracy: 0.4439\n",
            "Epoch 104/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.9831 - accuracy: 0.4569\n",
            "Epoch 105/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 1.9536 - accuracy: 0.4773\n",
            "Epoch 106/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 1.9161 - accuracy: 0.4717\n",
            "Epoch 107/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.9054 - accuracy: 0.4801\n",
            "Epoch 108/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.8873 - accuracy: 0.4754\n",
            "Epoch 109/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.8652 - accuracy: 0.4903\n",
            "Epoch 110/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 1.8313 - accuracy: 0.4940\n",
            "Epoch 111/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.8362 - accuracy: 0.4986\n",
            "Epoch 112/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.8250 - accuracy: 0.5032\n",
            "Epoch 113/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.8297 - accuracy: 0.5051\n",
            "Epoch 114/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.7727 - accuracy: 0.5107\n",
            "Epoch 115/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.7480 - accuracy: 0.5218\n",
            "Epoch 116/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 1.7295 - accuracy: 0.5283\n",
            "Epoch 117/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.6983 - accuracy: 0.5320\n",
            "Epoch 118/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.6777 - accuracy: 0.5385\n",
            "Epoch 119/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.6593 - accuracy: 0.5626\n",
            "Epoch 120/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.6420 - accuracy: 0.5570\n",
            "Epoch 121/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.6305 - accuracy: 0.5533\n",
            "Epoch 122/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.6175 - accuracy: 0.5672\n",
            "Epoch 123/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.5849 - accuracy: 0.5690\n",
            "Epoch 124/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.5669 - accuracy: 0.5783\n",
            "Epoch 125/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.5526 - accuracy: 0.5848\n",
            "Epoch 126/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.5198 - accuracy: 0.5783\n",
            "Epoch 127/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.5023 - accuracy: 0.6033\n",
            "Epoch 128/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.4813 - accuracy: 0.5968\n",
            "Epoch 129/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.4704 - accuracy: 0.6052\n",
            "Epoch 130/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.4531 - accuracy: 0.6126\n",
            "Epoch 131/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 1.4429 - accuracy: 0.6228\n",
            "Epoch 132/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.4179 - accuracy: 0.6182\n",
            "Epoch 133/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 1.4064 - accuracy: 0.6117\n",
            "Epoch 134/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 1.3898 - accuracy: 0.6339\n",
            "Epoch 135/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.3677 - accuracy: 0.6330\n",
            "Epoch 136/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.3435 - accuracy: 0.6265\n",
            "Epoch 137/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.3299 - accuracy: 0.6302\n",
            "Epoch 138/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.3109 - accuracy: 0.6571\n",
            "Epoch 139/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 1.2859 - accuracy: 0.6756\n",
            "Epoch 140/300\n",
            "9/9 [==============================] - 2s 197ms/step - loss: 1.2772 - accuracy: 0.6608\n",
            "Epoch 141/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 1.2504 - accuracy: 0.6747\n",
            "Epoch 142/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 1.2337 - accuracy: 0.6775\n",
            "Epoch 143/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.2285 - accuracy: 0.6747\n",
            "Epoch 144/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.2278 - accuracy: 0.6932\n",
            "Epoch 145/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 1.2333 - accuracy: 0.6766\n",
            "Epoch 146/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.1994 - accuracy: 0.6793\n",
            "Epoch 147/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.1829 - accuracy: 0.6867\n",
            "Epoch 148/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.1583 - accuracy: 0.6997\n",
            "Epoch 149/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.1502 - accuracy: 0.7146\n",
            "Epoch 150/300\n",
            "9/9 [==============================] - 3s 303ms/step - loss: 1.1229 - accuracy: 0.7062\n",
            "Epoch 151/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 1.0994 - accuracy: 0.7266\n",
            "Epoch 152/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.0853 - accuracy: 0.7155\n",
            "Epoch 153/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.0901 - accuracy: 0.7257\n",
            "Epoch 154/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 1.0831 - accuracy: 0.7303\n",
            "Epoch 155/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 1.0693 - accuracy: 0.7266\n",
            "Epoch 156/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 1.0398 - accuracy: 0.7479\n",
            "Epoch 157/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 1.0273 - accuracy: 0.7442\n",
            "Epoch 158/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 1.0100 - accuracy: 0.7461\n",
            "Epoch 159/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.9907 - accuracy: 0.7720\n",
            "Epoch 160/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.9871 - accuracy: 0.7488\n",
            "Epoch 161/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.9626 - accuracy: 0.7748\n",
            "Epoch 162/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.9551 - accuracy: 0.7785\n",
            "Epoch 163/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.9344 - accuracy: 0.7822\n",
            "Epoch 164/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.9321 - accuracy: 0.7868\n",
            "Epoch 165/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.9199 - accuracy: 0.7859\n",
            "Epoch 166/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.9213 - accuracy: 0.7887\n",
            "Epoch 167/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.8882 - accuracy: 0.7868\n",
            "Epoch 168/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.8836 - accuracy: 0.7933\n",
            "Epoch 169/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.8661 - accuracy: 0.8026\n",
            "Epoch 170/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.8561 - accuracy: 0.7998\n",
            "Epoch 171/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.8439 - accuracy: 0.8054\n",
            "Epoch 172/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.8303 - accuracy: 0.8174\n",
            "Epoch 173/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.8151 - accuracy: 0.8248\n",
            "Epoch 174/300\n",
            "9/9 [==============================] - 2s 204ms/step - loss: 0.8058 - accuracy: 0.8174\n",
            "Epoch 175/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.7969 - accuracy: 0.8184\n",
            "Epoch 176/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.7843 - accuracy: 0.8285\n",
            "Epoch 177/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.7790 - accuracy: 0.8387\n",
            "Epoch 178/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.7654 - accuracy: 0.8378\n",
            "Epoch 179/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.7580 - accuracy: 0.8387\n",
            "Epoch 180/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.7402 - accuracy: 0.8378\n",
            "Epoch 181/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.7338 - accuracy: 0.8489\n",
            "Epoch 182/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.7225 - accuracy: 0.8443\n",
            "Epoch 183/300\n",
            "9/9 [==============================] - 2s 201ms/step - loss: 0.7254 - accuracy: 0.8434\n",
            "Epoch 184/300\n",
            "9/9 [==============================] - 2s 198ms/step - loss: 0.7168 - accuracy: 0.8452\n",
            "Epoch 185/300\n",
            "9/9 [==============================] - 2s 199ms/step - loss: 0.6978 - accuracy: 0.8554\n",
            "Epoch 186/300\n",
            "9/9 [==============================] - 2s 200ms/step - loss: 0.6774 - accuracy: 0.8638\n",
            "Epoch 187/300\n",
            "9/9 [==============================] - 2s 202ms/step - loss: 0.6651 - accuracy: 0.8647\n",
            "Epoch 188/300\n",
            "9/9 [==============================] - 2s 203ms/step - loss: 0.6569 - accuracy: 0.8582\n",
            "Epoch 189/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.6531 - accuracy: 0.8665\n",
            "Epoch 190/300\n",
            "9/9 [==============================] - 2s 209ms/step - loss: 0.6574 - accuracy: 0.8591\n",
            "Epoch 191/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.6374 - accuracy: 0.8721\n",
            "Epoch 192/300\n",
            "9/9 [==============================] - 2s 207ms/step - loss: 0.6262 - accuracy: 0.8795\n",
            "Epoch 193/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.6179 - accuracy: 0.8897\n",
            "Epoch 194/300\n",
            "9/9 [==============================] - 2s 206ms/step - loss: 0.6107 - accuracy: 0.8684\n",
            "Epoch 195/300\n",
            "9/9 [==============================] - 2s 205ms/step - loss: 0.5928 - accuracy: 0.8953\n",
            "Epoch 196/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.5895 - accuracy: 0.8851\n",
            "Epoch 197/300\n",
            "9/9 [==============================] - 2s 210ms/step - loss: 0.5750 - accuracy: 0.8851\n",
            "Epoch 198/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.5716 - accuracy: 0.8888\n",
            "Epoch 199/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.5603 - accuracy: 0.8953\n",
            "Epoch 200/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.5434 - accuracy: 0.8981\n",
            "Epoch 201/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.5444 - accuracy: 0.8999\n",
            "Epoch 202/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.5215 - accuracy: 0.9027\n",
            "Epoch 203/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.5122 - accuracy: 0.9092\n",
            "Epoch 204/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.5039 - accuracy: 0.9120\n",
            "Epoch 205/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.5023 - accuracy: 0.9110\n",
            "Epoch 206/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.4862 - accuracy: 0.9184\n",
            "Epoch 207/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.4859 - accuracy: 0.9064\n",
            "Epoch 208/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.4728 - accuracy: 0.9249\n",
            "Epoch 209/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.4682 - accuracy: 0.9101\n",
            "Epoch 210/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.4582 - accuracy: 0.9296\n",
            "Epoch 211/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.4727 - accuracy: 0.9175\n",
            "Epoch 212/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.4579 - accuracy: 0.9194\n",
            "Epoch 213/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.4464 - accuracy: 0.9231\n",
            "Epoch 214/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.4444 - accuracy: 0.9231\n",
            "Epoch 215/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.4386 - accuracy: 0.9240\n",
            "Epoch 216/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.4152 - accuracy: 0.9333\n",
            "Epoch 217/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.4031 - accuracy: 0.9379\n",
            "Epoch 218/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.3978 - accuracy: 0.9351\n",
            "Epoch 219/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.3961 - accuracy: 0.9370\n",
            "Epoch 220/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.3862 - accuracy: 0.9425\n",
            "Epoch 221/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.3824 - accuracy: 0.9407\n",
            "Epoch 222/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.3711 - accuracy: 0.9416\n",
            "Epoch 223/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.3642 - accuracy: 0.9509\n",
            "Epoch 224/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.3627 - accuracy: 0.9472\n",
            "Epoch 225/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.3614 - accuracy: 0.9453\n",
            "Epoch 226/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.3518 - accuracy: 0.9509\n",
            "Epoch 227/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.3480 - accuracy: 0.9546\n",
            "Epoch 228/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.3430 - accuracy: 0.9481\n",
            "Epoch 229/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.3324 - accuracy: 0.9546\n",
            "Epoch 230/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.3316 - accuracy: 0.9481\n",
            "Epoch 231/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.3161 - accuracy: 0.9583\n",
            "Epoch 232/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.3128 - accuracy: 0.9555\n",
            "Epoch 233/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.3016 - accuracy: 0.9611\n",
            "Epoch 234/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2991 - accuracy: 0.9648\n",
            "Epoch 235/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.2942 - accuracy: 0.9611\n",
            "Epoch 236/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.2961 - accuracy: 0.9629\n",
            "Epoch 237/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2821 - accuracy: 0.9666\n",
            "Epoch 238/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2739 - accuracy: 0.9713\n",
            "Epoch 239/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2668 - accuracy: 0.9685\n",
            "Epoch 240/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.2634 - accuracy: 0.9703\n",
            "Epoch 241/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.2544 - accuracy: 0.9731\n",
            "Epoch 242/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.2511 - accuracy: 0.9731\n",
            "Epoch 243/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.2403 - accuracy: 0.9750\n",
            "Epoch 244/300\n",
            "9/9 [==============================] - 2s 221ms/step - loss: 0.2388 - accuracy: 0.9722\n",
            "Epoch 245/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.2339 - accuracy: 0.9759\n",
            "Epoch 246/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.2278 - accuracy: 0.9768\n",
            "Epoch 247/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.2218 - accuracy: 0.9759\n",
            "Epoch 248/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2192 - accuracy: 0.9759\n",
            "Epoch 249/300\n",
            "9/9 [==============================] - 2s 222ms/step - loss: 0.2151 - accuracy: 0.9778\n",
            "Epoch 250/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.2089 - accuracy: 0.9796\n",
            "Epoch 251/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.2059 - accuracy: 0.9787\n",
            "Epoch 252/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.2035 - accuracy: 0.9824\n",
            "Epoch 253/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.2022 - accuracy: 0.9833\n",
            "Epoch 254/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.1973 - accuracy: 0.9815\n",
            "Epoch 255/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1915 - accuracy: 0.9796\n",
            "Epoch 256/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1853 - accuracy: 0.9880\n",
            "Epoch 257/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1818 - accuracy: 0.9824\n",
            "Epoch 258/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.1756 - accuracy: 0.9889\n",
            "Epoch 259/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.1742 - accuracy: 0.9870\n",
            "Epoch 260/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.1698 - accuracy: 0.9861\n",
            "Epoch 261/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1680 - accuracy: 0.9880\n",
            "Epoch 262/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1653 - accuracy: 0.9861\n",
            "Epoch 263/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1605 - accuracy: 0.9907\n",
            "Epoch 264/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1563 - accuracy: 0.9917\n",
            "Epoch 265/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.1547 - accuracy: 0.9870\n",
            "Epoch 266/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1493 - accuracy: 0.9907\n",
            "Epoch 267/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.1457 - accuracy: 0.9907\n",
            "Epoch 268/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1456 - accuracy: 0.9880\n",
            "Epoch 269/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1399 - accuracy: 0.9926\n",
            "Epoch 270/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1343 - accuracy: 0.9935\n",
            "Epoch 271/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1341 - accuracy: 0.9935\n",
            "Epoch 272/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1297 - accuracy: 0.9954\n",
            "Epoch 273/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1264 - accuracy: 0.9926\n",
            "Epoch 274/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1253 - accuracy: 0.9963\n",
            "Epoch 275/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1208 - accuracy: 0.9963\n",
            "Epoch 276/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.1161 - accuracy: 0.9954\n",
            "Epoch 277/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.1164 - accuracy: 0.9935\n",
            "Epoch 278/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1129 - accuracy: 0.9972\n",
            "Epoch 279/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.1126 - accuracy: 0.9954\n",
            "Epoch 280/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.1092 - accuracy: 0.9963\n",
            "Epoch 281/300\n",
            "9/9 [==============================] - 2s 218ms/step - loss: 0.1082 - accuracy: 0.9944\n",
            "Epoch 282/300\n",
            "9/9 [==============================] - 2s 212ms/step - loss: 0.1049 - accuracy: 0.9972\n",
            "Epoch 283/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.1018 - accuracy: 0.9963\n",
            "Epoch 284/300\n",
            "9/9 [==============================] - 2s 217ms/step - loss: 0.0990 - accuracy: 0.9991\n",
            "Epoch 285/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0974 - accuracy: 0.9963\n",
            "Epoch 286/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0946 - accuracy: 0.9972\n",
            "Epoch 287/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0924 - accuracy: 0.9981\n",
            "Epoch 288/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0902 - accuracy: 0.9972\n",
            "Epoch 289/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0888 - accuracy: 0.9991\n",
            "Epoch 290/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0867 - accuracy: 0.9991\n",
            "Epoch 291/300\n",
            "9/9 [==============================] - 2s 216ms/step - loss: 0.0848 - accuracy: 1.0000\n",
            "Epoch 292/300\n",
            "9/9 [==============================] - 2s 219ms/step - loss: 0.0832 - accuracy: 1.0000\n",
            "Epoch 293/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.0816 - accuracy: 0.9981\n",
            "Epoch 294/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.0801 - accuracy: 1.0000\n",
            "Epoch 295/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.0779 - accuracy: 1.0000\n",
            "Epoch 296/300\n",
            "9/9 [==============================] - 2s 213ms/step - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 297/300\n",
            "9/9 [==============================] - 2s 220ms/step - loss: 0.0768 - accuracy: 1.0000\n",
            "Epoch 298/300\n",
            "9/9 [==============================] - 2s 214ms/step - loss: 0.0737 - accuracy: 0.9991\n",
            "Epoch 299/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0716 - accuracy: 1.0000\n",
            "Epoch 300/300\n",
            "9/9 [==============================] - 2s 215ms/step - loss: 0.0689 - accuracy: 1.0000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4afc957e90>"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "<h1><b>Text Generation</b></h1>"
      ],
      "metadata": {
        "id": "N1kOVeoMngKe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from random import randint\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "metadata": {
        "id": "YDZPxKvcg5gS"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Generate new text\n",
        "def generate_text(model, tokenizer, seq_len, seed_text, num_gen_words):\n",
        "    '''\n",
        "    INPUTS:\n",
        "    model : model that was trained on text data\n",
        "    tokenizer : tokenizer that was fit on text data\n",
        "    seq_len : length of training sequence\n",
        "    seed_text : raw string text to serve as the seed\n",
        "    num_gen_words : number of words to be generated by model\n",
        "    '''\n",
        "    \n",
        "    # Final Output\n",
        "    output_text = []\n",
        "    \n",
        "    # Intial Seed Sequence\n",
        "    input_text = seed_text\n",
        "    \n",
        "    # Create num_gen_words\n",
        "    for i in range(num_gen_words):\n",
        "        \n",
        "        # Take the input text string and encode it to a sequence\n",
        "        encoded_text = tokenizer.texts_to_sequences([input_text])[0]\n",
        "        \n",
        "        # Pad sequences to our trained rate (50 words in the video)\n",
        "        pad_encoded = pad_sequences([encoded_text], maxlen=seq_len, truncating='pre')\n",
        "        \n",
        "        # Predict Class Probabilities for each word\n",
        "        pred_word_ind = np.argmax(model.predict(pad_encoded, verbose=0)[0])\n",
        "        \n",
        "        # Grab word\n",
        "        pred_word = tokenizer.index_word[pred_word_ind] \n",
        "        \n",
        "        # Update the sequence of input text (shifting one over with the new word)\n",
        "        input_text += ' ' + pred_word\n",
        "        \n",
        "        output_text.append(pred_word)\n",
        "        \n",
        "    # Make it look like a sentence.\n",
        "    return ' '.join(output_text)"
      ],
      "metadata": {
        "id": "FYexPGYXhCVD"
      },
      "execution_count": 54,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "random.seed(101)\n",
        "random_pick = random.randint(0,len(word_sequences))"
      ],
      "metadata": {
        "id": "kjrDUn6hhmGE"
      },
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Choosing random text sequence\n",
        "random_seed_text = word_sequences[random_pick]"
      ],
      "metadata": {
        "id": "m0XkduvJhrnX"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text = ' '.join(random_seed_text)"
      ],
      "metadata": {
        "id": "fYOL8Iakhtp4"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "seed_text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "p5sg8Thhhy_C",
        "outputId": "ae712ba6-15dd-4c6d-8f54-633dff99ecb0"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'poured the contents of the pot into a colander thanks to the phone call the spaghetti was a little softer than al dente but it had'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_text(model,tokenizer,seq_len,seed_text=seed_text,num_gen_words=50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "xOSBOodFhz1k",
        "outputId": "15301fb1-38b1-4bda-96d5-c552ddfa02c4"
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'not been dealt a mortal blow i started eating and thinking understand each other understand each other ’s feelings in ten minutes what was she talking about maybe it was just a prank call or some new sales pitch in any case it had nothing to do with me after'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "hAPibj20h98x"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}